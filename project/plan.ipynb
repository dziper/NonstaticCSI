{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "841c7be04debbd1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- First draft of interfaces for models and train/test flow.\n",
    "- Interfaces for Predictor and the Test flow definitely need some changes to make sure the \"history\" is correct\n",
    "- The idea is to be able to swap out different Configs and Models for testing different scenarios"
   ],
   "id": "e87baf4d4bbafd7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:23:09.676384Z",
     "start_time": "2024-11-21T20:23:09.664104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, List, Generator\n",
    "\n",
    "# @dataclass(frozen=True)\n",
    "# class DataConfig\n",
    "#     num_rx_antennas: int\n",
    "#     num_tx_antennas: int\n",
    "#     num_subcarriers: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    num_rx_antennas: int\n",
    "    num_tx_antennas: int\n",
    "    num_subcarriers: int\n",
    "    # Additional options/configurations...\n",
    "    train_test_split: float\n",
    "    pca_model_path: str\n",
    "    predictor_path: str\n",
    "    kmeans_path: str\n",
    "    retrain_all: bool = True\n",
    "    predictor_window_size = 5\n",
    "\n",
    "\n",
    "# Not sure if we want to group stuff like this into sample\n",
    "@dataclass(frozen=True)\n",
    "class DataSample:\n",
    "    index: int\n",
    "    csi: np.ndarray\n",
    "    loc: np.ndarray\n",
    "    vel: np.ndarray\n",
    "    \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataWindow:\n",
    "    index: int\n",
    "    sample: DataSample  # Data Sample at index\n",
    "    previous: List[DataSample]  # Previous predictor_window_size elements\n",
    "    \n",
    "\n",
    "class Dataset:\n",
    "    csi_samples: np.ndarray\n",
    "    ue_locations: np.ndarray\n",
    "    ue_velocity: np.ndarray\n",
    "    \n",
    "    def __init__(self, cfg: Config, csis: np.ndarray, ue_locs: np.ndarray, ue_vels: np.ndarray, window_indexes: List[int]):\n",
    "        \"\"\"\n",
    "        :param csis:            Points to entire array of CSIs\n",
    "        :param ue_locs:         Points to entire array of Locs\n",
    "        :param ue_vels:         Points to entire array of Vels\n",
    "        :param window_indexes:  List of indices of end of prediction Window. \n",
    "            ie for each index, the previous cfg.predictor_window_size values will be used to predict the CSI at that index.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.cfg = cfg\n",
    "        self.csi_samples = csis\n",
    "        self.ue_locations = ue_locs\n",
    "        self.ue_velocity = ue_vels\n",
    "        self.window_indexes = window_indexes\n",
    "        assert all(self.window_indexes >= cfg.predictor_window_size)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index) -> DataSample:\n",
    "        return DataSample(index, self.csi_samples[index], self.ue_locations[index], self.ue_velocity[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.window_indexes)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # Iterate over Samples\n",
    "        for i in self.window_indexes:\n",
    "            yield self[i]\n",
    "    \n",
    "    def get_window(self, index) -> DataWindow:\n",
    "        return DataWindow(\n",
    "            index,\n",
    "            sample=self[index],\n",
    "            previous=[\n",
    "                self[idx] for idx in range(index - cfg.predictor_window_size, index)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def each_window(self) -> Generator[DataWindow]:\n",
    "        # Iterate over each Window\n",
    "        for i in self.window_indexes:\n",
    "            yield self.get_window(i)\n",
    "\n",
    "# We may want to move these class definitions into separate file\n",
    "\n",
    "class Model(ABC):\n",
    "    # Model interface for different predictors - basically anything that needs to be trained and then can predict stuff\n",
    "    @abstractmethod\n",
    "    def __init__(self):  # Instantiate Model hyperparameters\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def fit(self, data: np.ndarray):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def process(self, data: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def load(self, path):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def save(self, path):\n",
    "        pass\n",
    "\n",
    "\n",
    "# TODO: Implement Models\n",
    "class PCACompressor(Model):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        pass\n",
    "\n",
    "    def process(self, csis: np.ndarray) -> np.ndarray:\n",
    "        # return zdls\n",
    "        pass\n",
    "    \n",
    "    def decode(self, zdl: np.ndarray) -> np.ndarray:\n",
    "        # Go from zdl to csi space\n",
    "        pass\n",
    "\n",
    "    def load(self, path):\n",
    "        pass\n",
    "\n",
    "    def save(self, path):\n",
    "        pass\n",
    "\n",
    "\n",
    "class KMeansErrorCompressor(Model):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        pass\n",
    "\n",
    "    def process(self, data: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    def decode(self, error: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def load(self, path):\n",
    "        pass\n",
    "\n",
    "    def save(self, path):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CSIPredictor(Model):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        pass\n",
    "\n",
    "    def process(self, data: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    def load(self, path):\n",
    "        pass\n",
    "\n",
    "    def save(self, path):\n",
    "        pass\n",
    "\n"
   ],
   "id": "da8feb645a342ae8",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2387970700.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 66\u001B[0;36m\u001B[0m\n\u001B[0;31m    class Model(ABC):\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Processing\n",
   "id": "85b127cfe26ada76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:57:31.642797Z",
     "start_time": "2024-11-19T02:57:31.469029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Configure\n",
    "# Use this cfg variable whenever we need to access some constant\n",
    "cfg = Config(\n",
    "    num_rx_antennas=1,\n",
    "    num_tx_antennas=64,\n",
    "    num_subcarriers=80,\n",
    "    train_test_split=0.8\n",
    ")\n",
    "\n",
    "def load_data(folder: str) -> Tuple[Dataset, Dataset]:\n",
    "    ## TODO Load Data using cfg, train/test split\n",
    "    pass\n",
    "\n",
    "train_set, test_set = load_data(\"folder\")\n",
    "\n",
    "## TODO Add Noise"
   ],
   "id": "9f175868848da11d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'pca_model_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Configure\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Use this cfg variable whenever we need to access some constant\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m cfg \u001B[38;5;241m=\u001B[39m \u001B[43mConfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_rx_antennas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_tx_antennas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_subcarriers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m80\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_test_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data\u001B[39m(folder: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Dataset, Dataset]:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m## TODO Load Data using cfg, train/test split\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'pca_model_path'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Offline Training\n",
   "id": "fc2d0c7e9330205d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:57:41.837380Z",
     "start_time": "2024-11-19T02:57:41.797473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Train PCA\n",
    "def train_or_load(model: Model, data, path):\n",
    "    if not cfg.retrain_all and os.path.exists(path):\n",
    "        model.load(path)\n",
    "    else:\n",
    "        model.fit(data)\n",
    "        model.save(path)\n",
    "    \n",
    "pca = PCACompressor()\n",
    "train_or_load(pca, train_set.csi_samples, cfg.pca_model_path)\n",
    "zdl_train = pca.process(train_set.csi_samples)\n",
    "\n",
    "## TODO Bit Allocation?\n",
    "\n",
    "## Train Predictor\n",
    "predictor = CSIPredictor()\n",
    "train_or_load(predictor, zdl_train, cfg.predictor_path)  # TODO maybe want to also pass in location etc\n",
    "predicted_zdl = predictor.process(zdl_train)\n",
    "\n",
    "## TODO Compute Prediction Error\n",
    "prediction_error = zdl_train - predicted_zdl\n",
    "\n",
    "## Error Compression\n",
    "error_compressor = KMeansErrorCompressor()\n",
    "train_or_load(error_compressor, prediction_error, cfg.kmeans_path)\n",
    "\n",
    "# DL and UL each get trained pca, predictor, and error_compressor"
   ],
   "id": "427dd453549b54d4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Train PCA\u001B[39;00m\n\u001B[1;32m      2\u001B[0m pca \u001B[38;5;241m=\u001B[39m PCACompressor()\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcfg\u001B[49m\u001B[38;5;241m.\u001B[39mretrain_all \u001B[38;5;129;01mand\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(cfg\u001B[38;5;241m.\u001B[39mpca_path):\n\u001B[1;32m      4\u001B[0m     pca\u001B[38;5;241m.\u001B[39mload(cfg\u001B[38;5;241m.\u001B[39mpca_path)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "745a86e00640922c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Downlink Side\n",
    "zdl_test = pca.process(test_set.csi_samples)\n",
    "# Bit allocation?\n",
    "predicted_zdl_test = predictor.process(zdl_test)\n",
    "prediction_error_test = zdl_test - predicted_zdl\n",
    "compressed_error_test = error_compressor.process(predicted_zdl_test)\n",
    "\n",
    "# CHANNEL: Send compressed_error to UL\n",
    "\n",
    "## UL Side\n",
    "ul_predicted_error = error_compressor.decode(compressed_error_test)\n",
    "ul_predicted_zdl = predictor.process(zdl_test)  # TODO ? Shouldn't be test_set Might need to do this iteratively like loop over each sample and load the History \n",
    "ul_reconstructed_zdl = ul_predicted_error + ul_predicted_zdl\n",
    "ul_predicted_csi = pca.decode(ul_reconstructed_zdl)\n",
    "\n",
    "## TODO Compute Accuracy \n",
    "# test_set.csi_samples == ul_reconstructed_zdl"
   ],
   "id": "33d67e8c6013daae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize?\n",
   "id": "6f68095745a61347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dec1dfa29c1c3692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation\n",
    "- \"End to End\" Simulation\n",
    "- Show simulation of entire new \"test\" path made up of portions of paths that were trained on"
   ],
   "id": "d222025f94384969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class SimpleSimulator(ABC):\n",
    "    def __init__(self, cfg: Config, pca: PCACompressor, predictor: CSIPredictor, error_compressor: KMeansErrorCompressor):\n",
    "        # Given pretrained components\n",
    "        self.pca = pca\n",
    "        self.predictor = predictor\n",
    "        self.error_compressor = error_compressor\n",
    "        self.csi_history = []\n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def add_history(self, zdl):\n",
    "        self.csi_history.append(zdl)\n",
    "        if self.csi_history > self.cfg.predictor_window_size:\n",
    "            self.csi_history.pop(0)\n",
    "    \n",
    "    def set_history(self, csi_history: List[np.ndarray]):\n",
    "        self.csi_history = deepcopy(csi_history)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.csi_history = []\n",
    "        \n",
    "    def get_current_csi_window(self):\n",
    "        return self.csi_history[-cfg.predictor_window_size:]\n",
    "\n",
    "class DLSimulator(SimpleSimulator):\n",
    "    @abstractmethod\n",
    "    def simulate(self, sample: DataSample):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ULSimulator(SimpleSimulator):\n",
    "    @abstractmethod\n",
    "    def simulate(self, channel_input: np.ndarray) -> np.ndarray:\n",
    "        # Returns a CSI Estimation for this timestamp\n",
    "        pass\n",
    "\n",
    "\n",
    "class DLSimple(DLSimulator):\n",
    "    def simulate(self, sample: DataSample) -> np.ndarray:\n",
    "        # Returns Quantized Error for this timestep\n",
    "        zdl = self.pca.process(sample.csi)\n",
    "        predicted = self.predictor.process(self.get_current_csi_window())\n",
    "        error = zdl - predicted\n",
    "        compressed_error = self.error_compressor.process(error)\n",
    "        decompressed_error = self.error_compressor.decode(compressed_error)\n",
    "        reconstructed_zdl = predicted + decompressed_error\n",
    "        self.add_history(reconstructed_zdl)\n",
    "        return compressed_error  # Send on channel\n",
    "        \n",
    "\n",
    "class ULSimple(ULSimulator):\n",
    "    def simulate(self, compressed_error: np.ndarray)-> np.ndarray:\n",
    "        decompressed_error = self.error_compressor.decode(compressed_error)\n",
    "        predicted = self.predictor.process(self.get_current_csi_window())\n",
    "        reconstructed_zdl = predicted + decompressed_error\n",
    "        self.add_history(reconstructed_zdl)\n",
    "        return self.pca.decode(reconstructed_zdl)  # Estimated CSI on UL Side\n",
    "    \n",
    "class Evaluator:\n",
    "    def evaluate(self, sample: DataSample, predicted_csi: np.ndarray):\n",
    "        # Evaluate the sample from one time step\n",
    "        pass\n",
    "    \n",
    "    def report(self):\n",
    "        # Finalize evaluation and provide report\n",
    "        pass\n",
    "    \n",
    "    def visualize(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ],
   "id": "13e413696ea61e42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "# Load in pretrained components\n",
    "dl_sim: DLSimulator = DLSimple(cfg, pca, predictor, error_compressor)\n",
    "ul_sim: ULSimulator = ULSimple(cfg, pca, predictor, error_compressor)\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "for sample in dataset:\n",
    "    quantized_error = dl_sim.simulate(sample)\n",
    "    predicted_csi = ul_sim.simulate(quantized_error)\n",
    "    evaluator.evaluate(sample, predicted_csi)\n",
    "    \n",
    "evaluator.report()\n",
    "evaluator.visualize()"
   ],
   "id": "360e2e1ae780125b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
