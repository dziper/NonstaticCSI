{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "841c7be04debbd1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- First draft of interfaces for models and train/test flow.\n",
    "- Interfaces for Predictor and the Test flow definitely need some changes to make sure the \"history\" is correct\n",
    "- The idea is to be able to swap out different Configs and Models for testing different scenarios"
   ],
   "id": "e87baf4d4bbafd7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:23:09.676384Z",
     "start_time": "2024-11-21T20:23:09.664104Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2e72801e75d657d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Flow\n",
    "\n",
    "DataSample\n",
    "- CSI\n",
    "- Loc\n",
    "- Vel\n",
    "\n",
    "DataWindow\n",
    "- current DataSample\n",
    "- previous k DataSamples\n",
    "\n",
    "PCA\n",
    "- Fit: CSI Matrix\n",
    "    - Reduce Overhead? Part of PCA?\n",
    "- Process: CSI Matrix -> ZDL Matrix\n",
    "\n",
    "CSI Predictor\n",
    "- Fit: ZDL Matrix + Loc Matrix? + Vel Matrix?\n",
    "- Process: DataWindow (single) ->  \n",
    "\n",
    "Error Compressor\n",
    "- Includes bit allocation?\n",
    "- Train: Error Matrix (ZDL Matrix)\n",
    "- Test: Error Matrix (ZDL Matrix) -> CompressedErrors"
   ],
   "id": "86918716f91769b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Processing\n",
   "id": "85b127cfe26ada76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:57:31.642797Z",
     "start_time": "2024-11-19T02:57:31.469029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from dataset import Dataset, load_data\n",
    "from utils import Config\n",
    "\n",
    "## Configure\n",
    "# Use this cfg variable whenever we need to access some constant\n",
    "cfg = Config(\n",
    "    num_rx_antennas=1,\n",
    "    num_tx_antennas=64,\n",
    "    num_subcarriers=80,\n",
    "    train_test_split=0.8,\n",
    "    data_root=\"data/dataset1\"\n",
    ")\n",
    "\n",
    "train_set, test_set = load_data(\"folder\")"
   ],
   "id": "9f175868848da11d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'pca_model_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Configure\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Use this cfg variable whenever we need to access some constant\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m cfg \u001B[38;5;241m=\u001B[39m \u001B[43mConfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_rx_antennas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_tx_antennas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_subcarriers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m80\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_test_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data\u001B[39m(folder: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Dataset, Dataset]:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m## TODO Load Data using cfg, train/test split\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'pca_model_path'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Offline Training\n",
   "id": "fc2d0c7e9330205d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:57:41.837380Z",
     "start_time": "2024-11-19T02:57:41.797473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from reference_impl import ReferencePCA, ReferenceKmeans, NullPredictor\n",
    "from model import train_or_load\n",
    "\n",
    "pca = ReferencePCA()\n",
    "train_or_load(pca, cfg.pca_path, train_set.csi_samples)  # pca.fit() includes reduce overhead\n",
    "zdl_train = pca.process(train_set.csi_samples)\n",
    "zdl_train_windows = pca.process(train_set.csi_windows)\n",
    "\n",
    "## Train Predictor\n",
    "predictor = NullPredictor()\n",
    "train_or_load(predictor, cfg.predictor_path, zdl_train)  # TODO maybe want to also pass in location etc\n",
    "predicted_zdl = predictor.process(zdl_train)\n",
    "\n",
    "prediction_error = zdl_train - predicted_zdl\n",
    "\n",
    "## Error Compression\n",
    "error_compressor = ReferenceKmeans()\n",
    "train_or_load(error_compressor, cfg.kmeans_path, prediction_error)\n",
    "\n",
    "# DL and UL each get trained pca, predictor, and error_compressor"
   ],
   "id": "427dd453549b54d4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Train PCA\u001B[39;00m\n\u001B[1;32m      2\u001B[0m pca \u001B[38;5;241m=\u001B[39m PCACompressor()\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcfg\u001B[49m\u001B[38;5;241m.\u001B[39mretrain_all \u001B[38;5;129;01mand\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(cfg\u001B[38;5;241m.\u001B[39mpca_path):\n\u001B[1;32m      4\u001B[0m     pca\u001B[38;5;241m.\u001B[39mload(cfg\u001B[38;5;241m.\u001B[39mpca_path)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "745a86e00640922c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Downlink Side\n",
    "zdl_test = pca.process(test_set.csi_samples)\n",
    "# Bit allocation?\n",
    "predicted_zdl_test = predictor.process(zdl_test)\n",
    "prediction_error_test = zdl_test - predicted_zdl\n",
    "compressed_error_test = error_compressor.process(predicted_zdl_test)\n",
    "\n",
    "# CHANNEL: Send compressed_error to UL\n",
    "\n",
    "## UL Side\n",
    "ul_predicted_error = error_compressor.decode(compressed_error_test)\n",
    "ul_predicted_zdl = predictor.process(zdl_test)  # TODO ? Shouldn't be test_set Might need to do this iteratively like loop over each sample and load the History \n",
    "ul_reconstructed_zdl = ul_predicted_error + ul_predicted_zdl\n",
    "ul_predicted_csi = pca.decode(ul_reconstructed_zdl)\n",
    "\n",
    "## TODO Compute Accuracy \n",
    "# test_set.csi_samples == ul_reconstructed_zdl"
   ],
   "id": "33d67e8c6013daae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize?\n",
   "id": "6f68095745a61347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dec1dfa29c1c3692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation\n",
    "- \"End to End\" Simulation\n",
    "- Show simulation of entire new \"test\" path made up of portions of paths that were trained on"
   ],
   "id": "d222025f94384969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from copy import deepcopy\n",
   "id": "13e413696ea61e42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "# Load in pretrained components\n",
    "dl_sim: DLSimulator = DLSimple(cfg, pca, predictor, error_compressor)\n",
    "ul_sim: ULSimulator = ULSimple(cfg, pca, predictor, error_compressor)\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "for sample in dataset:\n",
    "    quantized_error = dl_sim.simulate(sample)\n",
    "    predicted_csi = ul_sim.simulate(quantized_error)\n",
    "    evaluator.evaluate(sample, predicted_csi)\n",
    "    \n",
    "evaluator.report()\n",
    "evaluator.visualize()"
   ],
   "id": "360e2e1ae780125b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
